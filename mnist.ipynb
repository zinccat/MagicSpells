{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luowl/miniconda3/envs/main/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import cv2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import os\n",
    "import os.path\n",
    "import shutil\n",
    "import string\n",
    "import sys\n",
    "import warnings\n",
    "from typing import Any, Callable, Dict, List, Optional, Tuple\n",
    "from urllib.error import URLError\n",
    "from torchvision.datasets.vision import VisionDataset\n",
    "from torchvision.datasets.utils import download_and_extract_archive, extract_archive, verify_str_arg, check_integrity\n",
    "import hashlib\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "def get_int(b: bytes) -> int:\n",
    "    return int(codecs.encode(b, \"hex\"), 16)\n",
    "\n",
    "\n",
    "SN3_PASCALVINCENT_TYPEMAP = {\n",
    "    8: torch.uint8,\n",
    "    9: torch.int8,\n",
    "    11: torch.int16,\n",
    "    12: torch.int32,\n",
    "    13: torch.float32,\n",
    "    14: torch.float64,\n",
    "}\n",
    "\n",
    "\n",
    "def read_sn3_pascalvincent_tensor(path: str, strict: bool = True) -> torch.Tensor:\n",
    "    \"\"\"Read a SN3 file in \"Pascal Vincent\" format (Lush file 'libidx/idx-io.lsh').\n",
    "    Argument may be a filename, compressed filename, or file object.\n",
    "    \"\"\"\n",
    "    # read\n",
    "    with open(path, \"rb\") as f:\n",
    "        data = f.read()\n",
    "    # parse\n",
    "    magic = get_int(data[0:4])\n",
    "    nd = magic % 256\n",
    "    ty = magic // 256\n",
    "    assert 1 <= nd <= 3\n",
    "    assert 8 <= ty <= 14\n",
    "    torch_type = SN3_PASCALVINCENT_TYPEMAP[ty]\n",
    "    s = [get_int(data[4 * (i + 1) : 4 * (i + 2)]) for i in range(nd)]\n",
    "\n",
    "    num_bytes_per_value = torch.iinfo(torch_type).bits // 8\n",
    "    # The MNIST format uses the big endian byte order. If the system uses little endian byte order by default,\n",
    "    # we need to reverse the bytes before we can read them with torch.frombuffer().\n",
    "    needs_byte_reversal = sys.byteorder == \"little\" and num_bytes_per_value > 1\n",
    "    parsed = torch.frombuffer(bytearray(data), dtype=torch_type, offset=(4 * (nd + 1)))\n",
    "    if needs_byte_reversal:\n",
    "        parsed = parsed.flip(0)\n",
    "\n",
    "    assert parsed.shape[0] == np.prod(s) or not strict\n",
    "    return parsed.view(*s)\n",
    "\n",
    "def read_label_file(path: str) -> torch.Tensor:\n",
    "    x = read_sn3_pascalvincent_tensor(path, strict=False)\n",
    "    assert x.dtype == torch.uint8\n",
    "    assert x.ndimension() == 1\n",
    "    return x.long()\n",
    "\n",
    "\n",
    "def read_image_file(path: str) -> torch.Tensor:\n",
    "    x = read_sn3_pascalvincent_tensor(path, strict=False)\n",
    "    assert x.dtype == torch.uint8\n",
    "    assert x.ndimension() == 3\n",
    "    return x\n",
    "\n",
    "\n",
    "class MNIST(VisionDataset):\n",
    "    \"\"\"`MNIST <http://yann.lecun.com/exdb/mnist/>`_ Dataset.\n",
    "\n",
    "    Args:\n",
    "        root (string): Root directory of dataset where ``MNIST/raw/train-images-idx3-ubyte``\n",
    "            and  ``MNIST/raw/t10k-images-idx3-ubyte`` exist.\n",
    "        train (bool, optional): If True, creates dataset from ``train-images-idx3-ubyte``,\n",
    "            otherwise from ``t10k-images-idx3-ubyte``.\n",
    "        download (bool, optional): If True, downloads the dataset from the internet and\n",
    "            puts it in root directory. If dataset is already downloaded, it is not\n",
    "            downloaded again.\n",
    "        transform (callable, optional): A function/transform that  takes in an PIL image\n",
    "            and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
    "        target_transform (callable, optional): A function/transform that takes in the\n",
    "            target and transforms it.\n",
    "    \"\"\"\n",
    "\n",
    "    mirrors = [\n",
    "        \"http://yann.lecun.com/exdb/mnist/\",\n",
    "        \"https://ossci-datasets.s3.amazonaws.com/mnist/\",\n",
    "    ]\n",
    "\n",
    "    resources = [\n",
    "        (\"train-images-idx3-ubyte.gz\", \"f68b3c2dcbeaaa9fbdd348bbdeb94873\"),\n",
    "        (\"train-labels-idx1-ubyte.gz\", \"d53e105ee54ea40749a09fcbcd1e9432\"),\n",
    "        (\"t10k-images-idx3-ubyte.gz\", \"9fb629c4189551a2d022fa330f9573f3\"),\n",
    "        (\"t10k-labels-idx1-ubyte.gz\", \"ec29112dd5afa0611ce80d1b7f02629c\"),\n",
    "    ]\n",
    "\n",
    "    training_file = \"training.pt\"\n",
    "    test_file = \"test.pt\"\n",
    "    classes = [\n",
    "        \"0 - zero\",\n",
    "        \"1 - one\",\n",
    "        \"2 - two\",\n",
    "        \"3 - three\",\n",
    "        \"4 - four\",\n",
    "        \"5 - five\",\n",
    "        \"6 - six\",\n",
    "        \"7 - seven\",\n",
    "        \"8 - eight\",\n",
    "        \"9 - nine\",\n",
    "    ]\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        root: str,\n",
    "        train: bool = True,\n",
    "        transform: Optional[Callable] = None,\n",
    "        target_transform: Optional[Callable] = None,\n",
    "        download: bool = False,\n",
    "    ) -> None:\n",
    "        super().__init__(root, transform=transform, target_transform=target_transform)\n",
    "        self.train = train  # training set or test set\n",
    "\n",
    "        if self._check_legacy_exist():\n",
    "            self.data, self.targets = self._load_legacy_data()\n",
    "            return\n",
    "\n",
    "        if download:\n",
    "            self.download()\n",
    "\n",
    "        if not self._check_exists():\n",
    "            raise RuntimeError(\"Dataset not found. You can use download=True to download it\")\n",
    "\n",
    "        self.data, self.targets = self._load_data()\n",
    "\n",
    "    def _check_legacy_exist(self):\n",
    "        processed_folder_exists = os.path.exists(self.processed_folder)\n",
    "        if not processed_folder_exists:\n",
    "            return False\n",
    "\n",
    "        return all(\n",
    "            check_integrity(os.path.join(self.processed_folder, file)) for file in (self.training_file, self.test_file)\n",
    "        )\n",
    "\n",
    "    def _load_legacy_data(self):\n",
    "        # This is for BC only. We no longer cache the data in a custom binary, but simply read from the raw data\n",
    "        # directly.\n",
    "        data_file = self.training_file if self.train else self.test_file\n",
    "        return torch.load(os.path.join(self.processed_folder, data_file))\n",
    "\n",
    "    def _load_data(self):\n",
    "        image_file = f\"{'train' if self.train else 't10k'}-images-idx3-ubyte\"\n",
    "        data = read_image_file(os.path.join(self.raw_folder, image_file))\n",
    "\n",
    "        label_file = f\"{'train' if self.train else 't10k'}-labels-idx1-ubyte\"\n",
    "        targets = read_label_file(os.path.join(self.raw_folder, label_file))\n",
    "\n",
    "        return data, targets\n",
    "\n",
    "    def __getitem__(self, index: int) -> Tuple[Any, Any]:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is index of the target class.\n",
    "        \"\"\"\n",
    "        img, target = self.data[index], int(self.targets[index])\n",
    "\n",
    "        # doing this so that it is consistent with all other datasets\n",
    "        # to return a PIL Image\n",
    "        img = Image.fromarray(img.numpy(), mode=\"L\")\n",
    "        img = np.array(img)\n",
    "        img[img>0] = 1\n",
    "        # img[img<=0.5] = 0\n",
    "        img = img*255\n",
    "        img = img.astype(np.uint8)\n",
    "        # img = cv2.ximgproc.thinning(img)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "        \n",
    "        \n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "\n",
    "    @property\n",
    "    def raw_folder(self) -> str:\n",
    "        return os.path.join(self.root, self.__class__.__name__, \"raw\")\n",
    "\n",
    "    @property\n",
    "    def processed_folder(self) -> str:\n",
    "        return os.path.join(self.root, self.__class__.__name__, \"processed\")\n",
    "\n",
    "    @property\n",
    "    def class_to_idx(self) -> Dict[str, int]:\n",
    "        return {_class: i for i, _class in enumerate(self.classes)}\n",
    "\n",
    "    def _check_exists(self) -> bool:\n",
    "        return all(\n",
    "            check_integrity(os.path.join(self.raw_folder, os.path.splitext(os.path.basename(url))[0]))\n",
    "            for url, _ in self.resources\n",
    "        )\n",
    "\n",
    "    def download(self) -> None:\n",
    "        \"\"\"Download the MNIST data if it doesn't exist already.\"\"\"\n",
    "\n",
    "        if self._check_exists():\n",
    "            return\n",
    "\n",
    "        os.makedirs(self.raw_folder, exist_ok=True)\n",
    "\n",
    "        # download files\n",
    "        for filename, md5 in self.resources:\n",
    "            for mirror in self.mirrors:\n",
    "                url = f\"{mirror}{filename}\"\n",
    "                try:\n",
    "                    print(f\"Downloading {url}\")\n",
    "                    download_and_extract_archive(url, download_root=self.raw_folder, filename=filename, md5=md5)\n",
    "                except URLError as error:\n",
    "                    print(f\"Failed to download (trying next):\\n{error}\")\n",
    "                    continue\n",
    "                finally:\n",
    "                    print()\n",
    "                break\n",
    "            else:\n",
    "                raise RuntimeError(f\"Error downloading {filename}\")\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        split = \"Train\" if self.train is True else \"Test\"\n",
    "        return f\"Split: {split}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                               transforms.Normalize(mean=[0.5],std=[0.5])])\n",
    "data_train = MNIST(root = \"./data/\",\n",
    "                            transform=transform,\n",
    "                            train = True,\n",
    "                            download = True)\n",
    "\n",
    "data_test = MNIST(root=\"./data/\",\n",
    "                           transform = transform,\n",
    "                           train = False)\n",
    "\n",
    "data_all = torch.utils.data.ConcatDataset([data_train, data_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader_train = torch.utils.data.DataLoader(dataset=data_train,\n",
    "                                                batch_size = 64,\n",
    "                                                shuffle = True,\n",
    "                                                num_workers = 2)\n",
    "\n",
    "data_loader_test = torch.utils.data.DataLoader(dataset=data_test,\n",
    "                                               batch_size = 64,\n",
    "                                               shuffle = True,\n",
    "                                                  num_workers = 2)\n",
    "data_loader_all = torch.utils.data.DataLoader(dataset=data_all,\n",
    "                                                batch_size = 64,\n",
    "                                                shuffle = True,\n",
    "                                                num_workers = 2)\n",
    "                                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f4b007bc610>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "images, labels = next(iter(data_loader_train))\n",
    "# img = torchvision.utils.make_grid(images)\n",
    "img = images[0]\n",
    "print(img.shape)\n",
    "img = img.numpy().transpose(1,2,0)\n",
    "std = [0.5,0.5,0.5]\n",
    "mean = [0.5,0.5,0.5]\n",
    "img = img*std+mean\n",
    "\n",
    "plt.imshow(img)\n",
    "# print(img.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1 = torch.nn.Sequential(torch.nn.Conv2d(1,64,kernel_size=3,stride=1,padding=1),\n",
    "                                         torch.nn.ReLU(),\n",
    "                                         torch.nn.Conv2d(64,128,kernel_size=3,stride=1,padding=1),\n",
    "                                         torch.nn.ReLU(),\n",
    "                                         torch.nn.MaxPool2d(stride=2,kernel_size=2))\n",
    "        self.dense = torch.nn.Sequential(torch.nn.Linear(14*14*128,1024),\n",
    "                                         torch.nn.ReLU(),\n",
    "                                         torch.nn.Dropout(p=0.5),\n",
    "                                         torch.nn.Linear(1024, 10))\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = x.view(-1, 14*14*128)\n",
    "        x = self.dense(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (dense): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=1024, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=1024, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training\n",
    "model = Model()\n",
    "cost = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "n_epochs = 5\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1094/1094 [00:08<00:00, 128.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is:0.0028, Train Accuracy is:111.4067%, Test Accuracy is:98.4700\n",
      "Epoch 1/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1094/1094 [00:09<00:00, 110.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is:0.0010, Train Accuracy is:114.6667%, Test Accuracy is:98.9600\n",
      "Epoch 2/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1094/1094 [00:10<00:00, 106.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is:0.0007, Train Accuracy is:115.2750%, Test Accuracy is:99.3100\n",
      "Epoch 3/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1094/1094 [00:10<00:00, 102.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is:0.0005, Train Accuracy is:115.6967%, Test Accuracy is:99.5800\n",
      "Epoch 4/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1094/1094 [00:10<00:00, 101.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is:0.0004, Train Accuracy is:115.8767%, Test Accuracy is:99.6200\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "for epoch in range(n_epochs):\n",
    "    running_loss = 0.0\n",
    "    running_correct = 0\n",
    "    print(\"Epoch {}/{}\".format(epoch, n_epochs))\n",
    "    print(\"-\"*10)\n",
    "    for data in tqdm(data_loader_all):\n",
    "        X_train, y_train = data\n",
    "        X_train = X_train.to(device)\n",
    "        y_train = y_train.to(device)\n",
    "        outputs = model(X_train)\n",
    "        _,pred = torch.max(outputs.data, 1)\n",
    "        optimizer.zero_grad()\n",
    "        loss = cost(outputs, y_train)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        running_correct += torch.sum(pred == y_train.data)\n",
    "    testing_correct = 0\n",
    "    for data in data_loader_test:\n",
    "        X_test, y_test = data\n",
    "        X_test, y_test = X_test.to(device), y_test.to(device)\n",
    "        outputs = model(X_test)\n",
    "        _, pred = torch.max(outputs.data, 1)\n",
    "        testing_correct += torch.sum(pred == y_test.data)\n",
    "    print(\"Loss is:{:.4f}, Train Accuracy is:{:.4f}%, Test Accuracy is:{:.4f}\".format(running_loss/len(data_train),\n",
    "                                                                                      100*running_correct/len(data_train),\n",
    "                                                                                      100*testing_correct/len(data_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"mnist.pkl\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d5863f077f85f396ce3efcec67c4a5e012c3c1b92fe1a124d511c388c1f237c6"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 ('main': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
